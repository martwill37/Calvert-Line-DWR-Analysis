{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- TEST function of mapping --------- # \n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.dates as mdates\n",
    "import cmocean as cm\n",
    "import glob\n",
    "import os\n",
    "import waypoint_distance as wd\n",
    "%matplotlib widget\n",
    "\n",
    "def plot_multiple_missions_map(glider_files, long_bounds=None, lat_bounds=None,\n",
    "                               topo_file=os.path.expanduser('~/Desktop/british_columbia_3_msl_2013.nc')):\n",
    "    \"\"\"\n",
    "    Plot multiple glider paths over bathymetry for the Calvert Line.\n",
    "\n",
    "    Parameters:\n",
    "    - glider_files: list of str, paths to NetCDF glider grid files\n",
    "    - topo_file: str, path to topo NetCDF file\n",
    "    - long_bounds, lat_bounds: optional map bounds\n",
    "    \"\"\"\n",
    "\n",
    "    # Load all datasets\n",
    "    datasets = [xr.open_dataset(os.path.expanduser(f)) for f in glider_files]\n",
    "    all_lons = np.concatenate([ds['longitude'].values for ds in datasets])\n",
    "    all_lats = np.concatenate([ds['latitude'].values for ds in datasets])\n",
    "\n",
    "    # Auto bounding box if not provided\n",
    "    if long_bounds is None:\n",
    "        long_bounds = [all_lons.min() - 0.5, all_lons.max() + 0.5]\n",
    "    if lat_bounds is None:\n",
    "        lat_bounds = [all_lats.min() - 0.5, all_lats.max() + 0.5]\n",
    "\n",
    "    # Load topo and subset\n",
    "    topo = xr.open_dataset(topo_file)\n",
    "    topo = topo.sel(\n",
    "        lon=slice(long_bounds[0], long_bounds[1]),\n",
    "        lat=slice(lat_bounds[0], lat_bounds[1])\n",
    "    )\n",
    "    topo_var = -topo['Band1']\n",
    "\n",
    "    # Set up plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 9), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax.set_extent(long_bounds + lat_bounds, crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Gridlines with lat/lon ticks only\n",
    "    gl = ax.gridlines(draw_labels=True, linestyle='--', alpha=0)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Bathymetry shading\n",
    "    levels = np.linspace(0, 410, 51)\n",
    "    contourf = ax.contourf(topo['lon'], topo['lat'], topo_var,\n",
    "                           levels=levels, cmap=cm.cm.deep, extend='both')\n",
    "    fig.colorbar(contourf, ax=ax, label='Depth (m)')\n",
    "\n",
    "    # 0 m contour (coastline)\n",
    "    ax.contour(topo['lon'], topo['lat'], topo_var, levels=[0.5], colors='black', linewidths=1)\n",
    "\n",
    "    # Time scaling for consistent colorbar\n",
    "    all_time_vals = np.concatenate([ds['time'].values for ds in datasets])\n",
    "    all_time_nums = mdates.date2num(all_time_vals)\n",
    "    vmin = all_time_nums.min()\n",
    "    vmax = all_time_nums.max()\n",
    "\n",
    "    for i, ds in enumerate(datasets):\n",
    "        lons = ds['longitude'].values\n",
    "        lats = ds['latitude'].values\n",
    "        time_vals = ds['time'].values\n",
    "        time_nums = mdates.date2num(time_vals)\n",
    "\n",
    "        label = os.path.basename(glider_files[i]).split('_')[0]\n",
    "        sc = ax.scatter(lons, lats, c=time_nums, cmap='seismic',\n",
    "                        vmin=vmin, vmax=vmax, s=5, transform=ccrs.PlateCarree(),\n",
    "                        zorder=5, label=label)\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(sc, ax=ax, orientation='vertical', pad=0.01, extend='both')\n",
    "    cbar.set_label('Date')\n",
    "    cbar.ax.yaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "    # Waypoint track overlay (optional)\n",
    "    waypoint_lon = [-127.950, -128.115, -128.243, -128.514, -128.646, -128.798]\n",
    "    waypoint_lat = [51.757, 51.705, 51.715, 51.450, 51.4165, 51.408]\n",
    "    # ax.plot(waypoint_lon, waypoint_lat, color='black', linestyle='-', linewidth=2, label='Transect')\n",
    "\n",
    "    ax.legend(title='Glider Missions')\n",
    "    ax.set_title('Glider Missions Map')\n",
    "    ax.set_aspect(1 / np.cos(np.deg2rad(np.mean(lat_bounds))))\n",
    "\n",
    "# Function to compare glider data:\n",
    "def plot_comparison_map(original_file, reprocessed_file,\n",
    "                        long_bounds=None, lat_bounds=None,\n",
    "                        topo_file=os.path.expanduser('~/CalvertLine/smith_sandwell_topo_v8_2.nc')):\n",
    "    \"\"\"\n",
    "    Plot original vs reprocessed glider path on a topo map.\n",
    "\n",
    "    Parameters:\n",
    "    - original_file: str, path to original _grid_delayed.nc file\n",
    "    - reprocessed_file: str, path to reprocessed _grid_delayed.nc file\n",
    "    - long_bounds, lat_bounds: optional map bounds\n",
    "    - topo_file: str, path to Smith & Sandwell topo NetCDF\n",
    "    \"\"\"\n",
    "    import xarray as xr\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import cmocean\n",
    "\n",
    "    # Load datasets\n",
    "    ds_old = xr.open_dataset(os.path.expanduser(original_file))\n",
    "    ds_new = xr.open_dataset(os.path.expanduser(reprocessed_file))\n",
    "\n",
    "    # Autoscale bounds if needed\n",
    "    all_lons = np.concatenate([ds_old.longitude.values, ds_new.longitude.values])\n",
    "    all_lats = np.concatenate([ds_old.latitude.values, ds_new.latitude.values])\n",
    "\n",
    "    if long_bounds is None:\n",
    "        long_bounds = [all_lons.min() - 0.5, all_lons.max() + 0.5]\n",
    "    if lat_bounds is None:\n",
    "        lat_bounds = [all_lats.min() - 0.5, all_lats.max() + 0.5]\n",
    "\n",
    "    # Load topo\n",
    "    topo = xr.open_dataset(topo_file)\n",
    "    topo = topo.sel(\n",
    "        longitude=slice(long_bounds[0] + 360, long_bounds[1] + 360),\n",
    "        latitude=slice(lat_bounds[0], lat_bounds[1]))\n",
    "    topo['longitude'] = topo['longitude'] - 360  # Convert to west longitudes\n",
    "\n",
    "    # Set up map\n",
    "    fig, ax = plt.subplots(figsize=(12, 9), subplot_kw={'projection': ccrs.PlateCarree()}, constrained_layout=True)\n",
    "    ax.set_extent(long_bounds + lat_bounds, crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(resolution='10m')\n",
    "    gl = ax.gridlines(draw_labels=True, color='gray', linestyle='--', alpha=0.5)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    ax.set_aspect(1 / np.cos(np.deg2rad(np.mean(lat_bounds))))\n",
    "\n",
    "    # Plot bathymetry\n",
    "    topo_var = -topo['ROSE']\n",
    "    levels = np.linspace(0, 4500, 21)\n",
    "    contour = ax.contourf(topo['longitude'], topo['latitude'], topo_var,\n",
    "                          levels=levels, cmap=cmocean.cm.deep, extend='both')\n",
    "    plt.colorbar(contour, ax=ax, label='Depth (m)')\n",
    "\n",
    "    # Plot glider tracks in fixed colors\n",
    "    ax.scatter(ds_old.longitude, ds_old.latitude, color='red', label='Original Track', s=5)\n",
    "    ax.scatter(ds_new.longitude, ds_new.latitude, color='blue', label='Reprocessed Track', s=1)\n",
    "\n",
    "    # # Add waypoint transect (optional)\n",
    "    # waypoint_lon = [-127.950, -128.115, -128.243, -128.514, -128.646, -128.798]\n",
    "    # waypoint_lat = [51.757, 51.705, 51.715, 51.450, 51.4165, 51.408]\n",
    "    # ax.plot(waypoint_lon, waypoint_lat, color='black', linestyle='--', linewidth=2, label='Waypoint Transect')\n",
    "\n",
    "    # Extract glider name from file path\n",
    "    glider_name = os.path.basename(original_file).split('_')[0]\n",
    "\n",
    "    # Finalize plot\n",
    "    ax.legend(title=f'Track Comparison for {glider_name}')\n",
    "    plt.title(f'Original vs Reprocessed Glider Track: {glider_name}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfc872",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_map(\n",
    "    original_file='/Users/martinwilliamson/CalvertLine/dfo-bb046-20200717_grid_delayed.nc',\n",
    "    reprocessed_file='~/CalvertLine_reprocessed/dfo-bb046-20200717_grid_delayed.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ae8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "reprocessed_dir = os.path.expanduser('~/CalvertLine_reprocessed')\n",
    "original_dir = os.path.expanduser('~/CalvertLine')\n",
    "\n",
    "# List all _grid_delayed.nc files in both directories\n",
    "reprocessed_files = sorted([\n",
    "    f for f in os.listdir(reprocessed_dir) if f.endswith('_grid_delayed.nc')\n",
    "])\n",
    "original_files = sorted([\n",
    "    f for f in os.listdir(original_dir) if f.endswith('_grid_delayed.nc')\n",
    "])\n",
    "\n",
    "# Find filenames present in both directories\n",
    "matched_files = sorted(set(reprocessed_files) & set(original_files))\n",
    "\n",
    "# Loop over matched files and run the plot function\n",
    "for filename in matched_files:\n",
    "    reprocessed_path = os.path.join(reprocessed_dir, filename)\n",
    "    original_path = os.path.join(original_dir, filename)\n",
    "\n",
    "    print(f\"Plotting comparison for {filename}\")\n",
    "    plot_comparison_map(original_path, reprocessed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "original_dir = os.path.expanduser('~/CalvertLine')\n",
    "reprocessed_dir = os.path.expanduser('~/CalvertLine_reprocessed')\n",
    "\n",
    "# Get files ending with _grid_delayed.nc in both dirs\n",
    "orig_files = {\n",
    "    f: os.path.getsize(os.path.join(original_dir, f))\n",
    "    for f in os.listdir(original_dir)\n",
    "    if f.endswith('_grid_delayed.nc')\n",
    "}\n",
    "reproc_files = {\n",
    "    f: os.path.getsize(os.path.join(reprocessed_dir, f))\n",
    "    for f in os.listdir(reprocessed_dir)\n",
    "    if f.endswith('_grid_delayed.nc')\n",
    "}\n",
    "\n",
    "# Create DataFrame comparing sizes\n",
    "all_files = sorted(set(orig_files.keys()) | set(reproc_files.keys()))\n",
    "data = []\n",
    "for f in all_files:\n",
    "    orig_size = orig_files.get(f, None)\n",
    "    reproc_size = reproc_files.get(f, None)\n",
    "    diff = (reproc_size - orig_size) if (orig_size and reproc_size) else None\n",
    "    data.append((f, orig_size, reproc_size, diff))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Filename', 'Original (bytes)', 'Reprocessed (bytes)', 'Difference'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b330674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "file1 = os.path.expanduser('~/CalvertLine/dfo-bb046-20200717_grid_delayed.nc')\n",
    "file2 = os.path.expanduser('~/CalvertLine_reprocessed/dfo-bb046-20200717_grid_delayed.nc')\n",
    "\n",
    "# Load datasets\n",
    "ds1 = xr.open_dataset(file1)\n",
    "ds2 = xr.open_dataset(file2)\n",
    "\n",
    "# 1. Global attributes\n",
    "print(\"ðŸ”¹ Global attribute differences:\")\n",
    "for key in set(ds1.attrs) | set(ds2.attrs):\n",
    "    if ds1.attrs.get(key) != ds2.attrs.get(key):\n",
    "        print(f\"  {key}:\\n    file1: {ds1.attrs.get(key)}\\n    file2: {ds2.attrs.get(key)}\")\n",
    "\n",
    "# 2. Variable presence\n",
    "vars1 = set(ds1.variables)\n",
    "vars2 = set(ds2.variables)\n",
    "print(\"\\nðŸ”¹ Variables only in file1:\", vars1 - vars2)\n",
    "print(\"ðŸ”¹ Variables only in file2:\", vars2 - vars1)\n",
    "\n",
    "# 3. Compare shapes and data values\n",
    "shared_vars = vars1 & vars2\n",
    "for var in sorted(shared_vars):\n",
    "    v1 = ds1[var]\n",
    "    v2 = ds2[var]\n",
    "    if v1.shape != v2.shape:\n",
    "        print(f\"\\nâš ï¸ Shape mismatch in '{var}': {v1.shape} vs {v2.shape}\")\n",
    "    else:\n",
    "        # Try numeric comparison\n",
    "        try:\n",
    "            diff = np.abs(v1.values - v2.values)\n",
    "            if np.nanmax(diff) > 1e-6:\n",
    "                print(f\"\\nðŸ”¹ Values differ in '{var}': max diff = {np.nanmax(diff):.2e}\")\n",
    "        except:\n",
    "            if not np.array_equal(v1.values, v2.values):\n",
    "                print(f\"\\nðŸ”¹ Non-numeric values differ in '{var}'\")\n",
    "\n",
    "# 4. Check for missing values\n",
    "for var in sorted(shared_vars):\n",
    "    nan1 = np.isnan(ds1[var].values).sum() if np.issubdtype(ds1[var].dtype, np.floating) else 0\n",
    "    nan2 = np.isnan(ds2[var].values).sum() if np.issubdtype(ds2[var].dtype, np.floating) else 0\n",
    "    if nan1 != nan2:\n",
    "        print(f\"\\nðŸ”¹ NaN count differs in '{var}': file1={nan1}, file2={nan2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "file1 = os.path.expanduser('~/CalvertLine/dfo-bb046-20200908_grid_delayed.nc')\n",
    "file2 = os.path.expanduser('~/CalvertLine_reprocessed/dfo-bb046-20200908_grid_delayed.nc')\n",
    "\n",
    "# Load datasets\n",
    "ds1 = xr.open_dataset(file1)\n",
    "ds2 = xr.open_dataset(file2)\n",
    "\n",
    "# 1. Global attribute differences\n",
    "print(\"ðŸ”¹ Global attribute differences:\")\n",
    "for key in set(ds1.attrs) | set(ds2.attrs):\n",
    "    if ds1.attrs.get(key) != ds2.attrs.get(key):\n",
    "        print(f\"  {key}:\\n    file1: {ds1.attrs.get(key)}\\n    file2: {ds2.attrs.get(key)}\")\n",
    "\n",
    "# 2. Variable presence\n",
    "vars1 = set(ds1.variables)\n",
    "vars2 = set(ds2.variables)\n",
    "print(\"\\nðŸ”¹ Variables only in file1:\", vars1 - vars2)\n",
    "print(\"ðŸ”¹ Variables only in file2:\", vars2 - vars1)\n",
    "\n",
    "# 3. Compare shapes and data values\n",
    "shared_vars = vars1 & vars2\n",
    "for var in sorted(shared_vars):\n",
    "    v1 = ds1[var]\n",
    "    v2 = ds2[var]\n",
    "    if v1.shape != v2.shape:\n",
    "        print(f\"\\nâš ï¸ Shape mismatch in '{var}': {v1.shape} vs {v2.shape}\")\n",
    "    else:\n",
    "        try:\n",
    "            diff = np.abs(v1.values - v2.values)\n",
    "            if np.nanmax(diff) > 1e-6:\n",
    "                print(f\"\\nðŸ”¹ Values differ in '{var}': max diff = {np.nanmax(diff):.2e}\")\n",
    "        except:\n",
    "            if not np.array_equal(v1.values, v2.values):\n",
    "                print(f\"\\nðŸ”¹ Non-numeric values differ in '{var}'\")\n",
    "\n",
    "# 4. NaN comparison\n",
    "for var in sorted(shared_vars):\n",
    "    if np.issubdtype(ds1[var].dtype, np.floating):\n",
    "        nan1 = np.isnan(ds1[var].values).sum()\n",
    "        nan2 = np.isnan(ds2[var].values).sum()\n",
    "        if nan1 != nan2:\n",
    "            print(f\"\\nðŸ”¹ NaN count differs in '{var}': file1={nan1}, file2={nan2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c20524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "file1 = os.path.expanduser('~/CalvertLine/dfo-marvin1003-20221018_grid_delayed.nc')\n",
    "file2 = os.path.expanduser('~/CalvertLine_reprocessed/dfo-marvin1003-20221018_grid_delayed.nc')\n",
    "\n",
    "# Load datasets\n",
    "ds1 = xr.open_dataset(file1)\n",
    "ds2 = xr.open_dataset(file2)\n",
    "\n",
    "# 1. Global attribute differences\n",
    "print(\"ðŸ”¹ Global attribute differences:\")\n",
    "for key in set(ds1.attrs) | set(ds2.attrs):\n",
    "    if ds1.attrs.get(key) != ds2.attrs.get(key):\n",
    "        print(f\"  {key}:\\n    file1: {ds1.attrs.get(key)}\\n    file2: {ds2.attrs.get(key)}\")\n",
    "\n",
    "# 2. Variable presence\n",
    "vars1 = set(ds1.variables)\n",
    "vars2 = set(ds2.variables)\n",
    "print(\"\\nðŸ”¹ Variables only in file1:\", vars1 - vars2)\n",
    "print(\"ðŸ”¹ Variables only in file2:\", vars2 - vars1)\n",
    "\n",
    "# 3. Compare shapes and data values\n",
    "shared_vars = vars1 & vars2\n",
    "for var in sorted(shared_vars):\n",
    "    v1 = ds1[var]\n",
    "    v2 = ds2[var]\n",
    "    if v1.shape != v2.shape:\n",
    "        print(f\"\\nâš ï¸ Shape mismatch in '{var}': {v1.shape} vs {v2.shape}\")\n",
    "    else:\n",
    "        try:\n",
    "            diff = np.abs(v1.values - v2.values)\n",
    "            if np.nanmax(diff) > 1e-6:\n",
    "                print(f\"\\nðŸ”¹ Values differ in '{var}': max diff = {np.nanmax(diff):.2e}\")\n",
    "        except:\n",
    "            if not np.array_equal(v1.values, v2.values):\n",
    "                print(f\"\\nðŸ”¹ Non-numeric values differ in '{var}'\")\n",
    "\n",
    "# 4. NaN comparison\n",
    "for var in sorted(shared_vars):\n",
    "    if np.issubdtype(ds1[var].dtype, np.floating):\n",
    "        nan1 = np.isnan(ds1[var].values).sum()\n",
    "        nan2 = np.isnan(ds2[var].values).sum()\n",
    "        if nan1 != nan2:\n",
    "            print(f\"\\nðŸ”¹ NaN count differs in '{var}': file1={nan1}, file2={nan2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25841e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Which files are not in both directories? \n",
    "\n",
    "\n",
    "reprocessed_dir = os.path.expanduser('~/CalvertLine_reprocessed')\n",
    "original_dir = os.path.expanduser('~/CalvertLine')\n",
    "\n",
    "# List all _grid_delayed.nc files in both directories\n",
    "reprocessed_files = set([\n",
    "    f for f in os.listdir(reprocessed_dir) if f.endswith('_grid_delayed.nc')\n",
    "])\n",
    "original_files = set([\n",
    "    f for f in os.listdir(original_dir) if f.endswith('_grid_delayed.nc')\n",
    "])\n",
    "\n",
    "# Files missing in either direction\n",
    "only_in_reprocessed = sorted(reprocessed_files - original_files)\n",
    "only_in_original = sorted(original_files - reprocessed_files)\n",
    "\n",
    "# Print differences\n",
    "if only_in_reprocessed:\n",
    "    print(\"Files only in reprocessed directory:\")\n",
    "    for f in only_in_reprocessed:\n",
    "        print(f\"  {f}\")\n",
    "\n",
    "if only_in_original:\n",
    "    print(\"Files only in original directory:\")\n",
    "    for f in only_in_original:\n",
    "        print(f\"  {f}\")\n",
    "\n",
    "# Optional: matched files if needed\n",
    "matched_files = sorted(reprocessed_files & original_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
