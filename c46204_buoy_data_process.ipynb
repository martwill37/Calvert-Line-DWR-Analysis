{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785275df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = '~/Desktop/Summer 2025 Python/c46204.csv'\n",
    "ds = pd.read_csv(file_path)\n",
    "\n",
    "# Parse datetime\n",
    "ds['DATE'] = pd.to_datetime(ds['DATE'], format='%m/%d/%Y %H:%M')\n",
    "ds = ds[(ds['DATE'] >= '2014-01-01') & (ds['DATE'] <= '2026-01-01')]\n",
    "\n",
    "# Extract wind direction and speed (first set of columns)\n",
    "ds['WDIR'] = pd.to_numeric(ds['WDIR'], errors='coerce')     # Wind Direction (degrees)\n",
    "ds['WSPD'] = pd.to_numeric(ds['WSPD'], errors='coerce')     # Wind Speed (m/s or knots)\n",
    "ds['SSTP'] = pd.to_numeric(ds['SSTP'], errors='coerce')     # Sea surface temp\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Wind speed\n",
    "ax1.scatter(ds['DATE'], ds['WSPD'], label='Wind Speed', color='blue', s = 1)\n",
    "ax1.set_ylabel('Wind Speed (m/s)', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Formatting\n",
    "ax1.set_title('Wind Speed and Direction from C46204')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.xaxis.set_major_formatter(DateFormatter('%b %d\\n%Y'))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Wind speed\n",
    "ax1.scatter(ds['DATE'], ds['SSTP'], label='Sea Surface Temperature', color='red', s = 1)\n",
    "ax1.set_ylabel('Sea Surface Temperature', color='red')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Formatting\n",
    "ax1.set_title('Sea Surface Temperature from C46204')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.xaxis.set_major_formatter(DateFormatter('%b %d\\n%Y'))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6381b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "\n",
    "# --- Load data ---\n",
    "file_path = '~/Desktop/Summer 2025 Python/c46204.csv'\n",
    "ds = pd.read_csv(file_path)\n",
    "\n",
    "# --- Parse datetime & filter ---\n",
    "ds['DATE'] = pd.to_datetime(ds['DATE'], format='%m/%d/%Y %H:%M')\n",
    "ds = ds[(ds['DATE'] >= '2021-01-01') & (ds['DATE'] <= '2026-01-01')]\n",
    "\n",
    "# --- Ensure numeric ---\n",
    "ds['WDIR'] = pd.to_numeric(ds['WDIR'], errors='coerce')   # deg true (from)\n",
    "ds['WSPD'] = pd.to_numeric(ds['WSPD'], errors='coerce')   # m/s\n",
    "ds['ATMS'] = pd.to_numeric(ds['ATMS'], errors='coerce')   # mbar (hPa)\n",
    "ds['DRYT'] = pd.to_numeric(ds.get('DRYT'), errors='coerce')  # air temp (°C), if present\n",
    "\n",
    "# --- Air density from pressure & temp ---\n",
    "# ATMS: mbar -> Pa (×100). DRYT: °C -> K (+273.15)\n",
    "# ρ_air = p / (R * T), R = 287.06 J kg^-1 K^-1\n",
    "R = 287.06\n",
    "p_Pa = ds['ATMS'] * 100.0\n",
    "T_K  = 273.15 + ds['DRYT']\n",
    "ds['rho_air'] = p_Pa / (R * T_K)\n",
    "\n",
    "# # Fallback where missing/non-finite -> 1.225 kg/m^3\n",
    "# rho_air = rho_air.where(np.isfinite(rho_air), other=1.225)\n",
    "# ds['rho_air'] = rho_air\n",
    "\n",
    "# --- Function: Ekman transport projected onto fixed 135° True OFFSHORE axis\n",
    "# Convention HERE (PFEL/Bakun): OFFSHORE (toward 135°) => POSITIVE\n",
    "def compute_ekman_transport_bakun(speed, dir_from_deg_true, rho_air,\n",
    "                                  phi_for_f=51.38, Cd=1.3e-3, rho_w=1025.0):\n",
    "    \"\"\"\n",
    "    Returns M_offshore (m^2/s per unit width) projected along 135° True,\n",
    "    with POSITIVE = offshore (upwelling-favorable), NEGATIVE = onshore.\n",
    "    \"\"\"\n",
    "    # Wind (met 'from') -> east/north (toward)\n",
    "    th = np.deg2rad(dir_from_deg_true)\n",
    "    u = -speed * np.sin(th)  # east\n",
    "    v = -speed * np.cos(th)  # north\n",
    "    W = np.hypot(u, v)\n",
    "\n",
    "    # Stress (east,north)\n",
    "    tau_u = rho_air * Cd * W * u\n",
    "    tau_v = rho_air * Cd * W * v\n",
    "\n",
    "    # Ekman transport vector (east,north): M = (k × tau)/(rho_w f)\n",
    "    f = 2.0 * 7.2921e-5 * np.sin(np.deg2rad(phi_for_f))\n",
    "    M_e = -tau_v / (rho_w * f)  # east\n",
    "    M_n =  tau_u / (rho_w * f)  # north\n",
    "\n",
    "    # Unit vector TOWARD 135° (PFEL offshore axis)\n",
    "    theta_off = np.deg2rad(135.0)\n",
    "    e_off = (np.sin(theta_off), np.cos(theta_off))  # (east, north)\n",
    "\n",
    "    # Project: positive along e_off = offshore (Bakun positive)\n",
    "    M_off = M_e * e_off[0] + M_n * e_off[1]\n",
    "    return M_off\n",
    "\n",
    "# --- Calculate Bakun-style index per 100 m shoreline ---\n",
    "ds['M'] = compute_ekman_transport_bakun(ds['WSPD'], ds['WDIR'], ds['rho_air']) * 100.0  # m^3/s per 100 m\n",
    "\n",
    "# --- Plot as bars (positive = upwelling/offshore; negative = downwelling/onshore) ---\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "colors = np.where(ds['M'] >= 0, 'steelblue', 'tomato')  # blue = upwelling (+), red = downwelling (-)\n",
    "ax.bar(ds['DATE'], ds['M'], width=1.0, color=colors, align='center')\n",
    "\n",
    "ax.axhline(0, color='k', ls='--', lw=0.8)\n",
    "ax.set_ylabel(r'Bakun Upwelling Index (m$^3$ s$^{-1}$ per 100 m)', fontsize=12)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_title('Bakun Index at C46204 (Offshore Axis = 135° True; + = Upwelling)', fontsize=14)\n",
    "\n",
    "date_fmt = DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "# Path to your PFEL daily file that contains the header and the \"YYYYMMDD Index\" table\n",
    "pfel_path = Path('~/Desktop/p05dayac.all').expanduser()\n",
    "\n",
    "# Optional date filter (set to None to keep all)\n",
    "DATE_START = '2021-01-01'          # e.g., '2021-01-01'\n",
    "DATE_END   = None          # e.g., '2026-01-01'\n",
    "\n",
    "# Toggle a 4-week time-based rolling mean bar plot instead of daily\n",
    "USE_4W_ROLLING = False     # set True for rolling bars\n",
    "\n",
    "# -----------------------------\n",
    "# Parse the PFEL file\n",
    "# -----------------------------\n",
    "# Find the row index where the actual two-column table starts (line after \"YYYYMMDD Index\")\n",
    "with open(pfel_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "start_idx = None\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip().startswith('YYYYMMDD'):\n",
    "        start_idx = i + 1  # data begins after this line\n",
    "        break\n",
    "\n",
    "if start_idx is None:\n",
    "    raise ValueError(\"Couldn't find the 'YYYYMMDD Index' header in the file.\")\n",
    "\n",
    "# Read the two columns (YYYYMMDD, Index); whitespace-delimited\n",
    "df = pd.read_csv(\n",
    "    pfel_path,\n",
    "    delim_whitespace=True,\n",
    "    header=None,\n",
    "    names=['DATE', 'Index'],\n",
    "    skiprows=start_idx\n",
    ")\n",
    "\n",
    "# Drop any non-numeric DATE rows (e.g., trailing lines)\n",
    "df = df[pd.to_numeric(df['DATE'], errors='coerce').notna()].copy()\n",
    "\n",
    "# Convert types\n",
    "df['DATE'] = pd.to_datetime(df['DATE'].astype(str), format='%Y%m%d')\n",
    "df['Index'] = pd.to_numeric(df['Index'], errors='coerce')\n",
    "\n",
    "# Replace -9999 with NaN and drop\n",
    "df.loc[df['Index'] == -9999, 'Index'] = np.nan\n",
    "df = df.dropna(subset=['Index'])\n",
    "\n",
    "# Optional date filter\n",
    "if DATE_START is not None:\n",
    "    df = df[df['DATE'] >= pd.to_datetime(DATE_START)]\n",
    "if DATE_END is not None:\n",
    "    df = df[df['DATE'] <= pd.to_datetime(DATE_END)]\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare series to plot\n",
    "# -----------------------------\n",
    "# PFEL convention: Positive = offshore (upwelling), Negative = onshore (downwelling)\n",
    "# Units already: m^3 s^-1 per 100 m coastline (from PFEL docs)\n",
    "df = df.sort_values('DATE').set_index('DATE')\n",
    "\n",
    "if USE_4W_ROLLING:\n",
    "    series = df['Index'].rolling(window='28D', min_periods=1).mean()\n",
    "    plot_title_suffix = ' (4-week rolling mean)'\n",
    "else:\n",
    "    series = df['Index']\n",
    "    plot_title_suffix = ' (Daily)'\n",
    "\n",
    "# -----------------------------\n",
    "# Plot bars matching your C46204 style\n",
    "# -----------------------------\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "colors = np.where(series.values >= 0, 'steelblue', 'tomato')  # upwelling (+) vs downwelling (−)\n",
    "ax.bar(series.index, series.values, width=1.0, color=colors, align='center')\n",
    "\n",
    "ax.axhline(0, color='k', ls='--', lw=0.8)\n",
    "ax.set_ylabel(r'Bakun Upwelling Index (m$^3$ s$^{-1}$ per 100 m)', fontsize=12)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_title('Bakun Index at 51°N, 131°W — + Offshore (Upwelling)' + plot_title_suffix, fontsize=14)\n",
    "\n",
    "date_fmt = DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb346e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# Config (edit paths)\n",
    "# =========================\n",
    "c46204_path = Path('~/Desktop/Summer 2025 Python/c46204.csv').expanduser()\n",
    "pfel_path   = Path('~/Desktop/p05dayac.all').expanduser()  # PFEL daily Bakun text file\n",
    "out_path    = Path('~/Desktop/Summer 2025 Python/bakun_combined_daily.csv').expanduser()\n",
    "\n",
    "DATE_START = '2000-01-01'   # or None\n",
    "DATE_END   = '2026-01-01'   # or None\n",
    "assume_knots = False        # set True if WSPD in c46204 is in knots\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def compute_ekman_transport_bakun(speed, dir_from_deg_true, rho_air,\n",
    "                                  phi_for_f=51.38, Cd=1.3e-3, rho_w=1025.0):\n",
    "    \"\"\"\n",
    "    Returns M_offshore (m^2/s per unit width) projected along 135° True,\n",
    "    with POSITIVE = offshore (upwelling-favorable), NEGATIVE = onshore.\n",
    "    Inputs can be pandas Series; vectorized operations are used.\n",
    "    \"\"\"\n",
    "    th = np.deg2rad(dir_from_deg_true)\n",
    "    u = -speed * np.sin(th)  # eastward wind (toward)\n",
    "    v = -speed * np.cos(th)  # northward wind (toward)\n",
    "    W = np.hypot(u, v)\n",
    "\n",
    "    tau_u = rho_air * Cd * W * u\n",
    "    tau_v = rho_air * Cd * W * v\n",
    "\n",
    "    f = 2.0 * 7.2921e-5 * np.sin(np.deg2rad(phi_for_f))\n",
    "    M_e = -tau_v / (rho_w * f)  # east\n",
    "    M_n =  tau_u / (rho_w * f)  # north\n",
    "\n",
    "    theta_off = np.deg2rad(135.0)  # PFEL offshore axis\n",
    "    e_off_e = np.sin(theta_off)\n",
    "    e_off_n = np.cos(theta_off)\n",
    "\n",
    "    M_off = M_e * e_off_e + M_n * e_off_n\n",
    "    return M_off  # m^2/s per unit width\n",
    "\n",
    "def parse_pfel_daily_file(pfel_file_path):\n",
    "    \"\"\"\n",
    "    Parses a PFEL daily Bakun index file that includes a header and a\n",
    "    'YYYYMMDD Index' table. Returns a DataFrame with columns: DATE, PFEL (m^3/s per 100 m).\n",
    "    \"\"\"\n",
    "    with open(pfel_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    start_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('YYYYMMDD'):\n",
    "            start_idx = i + 1\n",
    "            break\n",
    "    if start_idx is None:\n",
    "        raise ValueError(\"Couldn't find the 'YYYYMMDD' header in PFEL file.\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        pfel_file_path,\n",
    "        delim_whitespace=True,\n",
    "        header=None,\n",
    "        names=['DATE', 'Index'],\n",
    "        skiprows=start_idx\n",
    "    )\n",
    "    df = df[pd.to_numeric(df['DATE'], errors='coerce').notna()].copy()\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'].astype(str), format='%Y%m%d')\n",
    "    df['Index'] = pd.to_numeric(df['Index'], errors='coerce')\n",
    "    df.loc[df['Index'] == -9999, 'Index'] = np.nan\n",
    "    df = df.dropna(subset=['Index']).sort_values('DATE').reset_index(drop=True)\n",
    "    df = df.rename(columns={'Index': 'PFEL'})\n",
    "    return df[['DATE', 'PFEL']]\n",
    "\n",
    "# =========================\n",
    "# 1) Load & process C46204 buoy -> daily Bakun-style index (per 100 m)\n",
    "# =========================\n",
    "ds = pd.read_csv(c46204_path)\n",
    "ds['DATE'] = pd.to_datetime(ds['DATE'], format='%m/%d/%Y %H:%M', errors='coerce')\n",
    "\n",
    "if DATE_START is not None:\n",
    "    ds = ds[ds['DATE'] >= pd.to_datetime(DATE_START)]\n",
    "if DATE_END is not None:\n",
    "    ds = ds[ds['DATE'] <= pd.to_datetime(DATE_END)]\n",
    "\n",
    "# Ensure numeric\n",
    "for col in ['WDIR', 'WSPD', 'ATMS', 'DRYT']:\n",
    "    if col in ds.columns:\n",
    "        ds[col] = pd.to_numeric(ds[col], errors='coerce')\n",
    "\n",
    "# Optional: convert knots to m/s\n",
    "if assume_knots and 'WSPD' in ds.columns:\n",
    "    ds['WSPD'] = ds['WSPD'] * 0.514444\n",
    "\n",
    "# Air density from pressure & dry-air temperature (fallbacks applied)\n",
    "# ATMS given in mbar (hPa) -> Pa; DRYT in °C -> K; R = 287.06 J/(kg K)\n",
    "R = 287.06\n",
    "p_Pa = (ds['ATMS'] * 100.0) if 'ATMS' in ds.columns else np.nan\n",
    "T_K  = (273.15 + ds['DRYT']) if 'DRYT' in ds.columns else 273.15 + 15.0\n",
    "rho_air = p_Pa / (R * T_K)\n",
    "rho_air = rho_air.where(np.isfinite(rho_air), other=1.225)  # fallback to 1.225 kg/m^3\n",
    "\n",
    "# Compute per-sample M (m^2/s), then convert to per-100 m shoreline\n",
    "M_off = compute_ekman_transport_bakun(\n",
    "    speed=ds['WSPD'],\n",
    "    dir_from_deg_true=ds['WDIR'],\n",
    "    rho_air=rho_air\n",
    ")\n",
    "ds['C46204'] = M_off * 100.0  # m^3/s per 100 m\n",
    "\n",
    "# Daily average (date-only, local naive)\n",
    "ds['DATE_DAY'] = ds['DATE'].dt.floor('D')\n",
    "buoy_daily = (ds.groupby('DATE_DAY', as_index=False)['C46204']\n",
    "                .mean()\n",
    "                .rename(columns={'DATE_DAY': 'DATE'}))\n",
    "\n",
    "# =========================\n",
    "# 2) Load & process PFEL daily file\n",
    "# =========================\n",
    "pfel_daily = parse_pfel_daily_file(pfel_path)\n",
    "\n",
    "# Optional: clip PFEL to buoy date window to ensure overlap\n",
    "start = buoy_daily['DATE'].min()\n",
    "end   = buoy_daily['DATE'].max()\n",
    "pfel_daily = pfel_daily[(pfel_daily['DATE'] >= start) & (pfel_daily['DATE'] <= end)]\n",
    "\n",
    "# =========================\n",
    "# 3) Merge on DATE and save\n",
    "# =========================\n",
    "combined = (pd.merge(buoy_daily, pfel_daily, on='DATE', how='inner')\n",
    "              .sort_values('DATE')\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "# Columns: DATE, C46204 (m^3/s per 100 m), PFEL (m^3/s per 100 m)\n",
    "combined.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(combined)} daily rows to: {out_path}\")\n",
    "print(combined.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2432e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Load merged daily CSV from the previous step ---\n",
    "combined_path = Path('~/Desktop/Summer 2025 Python/bakun_combined_daily.csv').expanduser()\n",
    "df = pd.read_csv(combined_path, parse_dates=['DATE']).sort_values('DATE')\n",
    "\n",
    "# --- Compute per-panel ranges for sizing ---\n",
    "def total_range(series):\n",
    "    if not series.notna().any():\n",
    "        return 1.0\n",
    "    return float(series.max() - series.min())\n",
    "\n",
    "range_c = total_range(df['C46204'])\n",
    "range_p = total_range(df['PFEL'])\n",
    "\n",
    "height_ratios = [range_c, range_p]\n",
    "\n",
    "# --- Colors by sign ---\n",
    "colors_c = np.where(df['C46204'] >= 0, 'steelblue', 'tomato')\n",
    "colors_p = np.where(df['PFEL']   >= 0, 'steelblue', 'tomato')\n",
    "\n",
    "# --- Make subplots ---\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    nrows=2, ncols=1, figsize=(12, 8), sharex=True,\n",
    "    gridspec_kw={'height_ratios': height_ratios}\n",
    ")\n",
    "\n",
    "# --- Top panel: C46204 ---\n",
    "ax1.bar(df['DATE'], df['C46204'], width=1.0, color=colors_c, align='center')\n",
    "ax1.axhline(0, color='k', ls='--', lw=0.8)\n",
    "ax1.set_ylabel(r'C46204 (m$^3$ s$^{-1}$ per 100 m)', fontsize=12)\n",
    "ax1.set_title('Daily Bakun Index — C46204 vs PFEL 51°N, 131°W', fontsize=14)\n",
    "ax1.set_ylim(df['C46204'].min(), df['C46204'].max())\n",
    "\n",
    "# --- Bottom panel: PFEL ---\n",
    "ax2.bar(df['DATE'], df['PFEL'], width=1.0, color=colors_p, align='center')\n",
    "ax2.axhline(0, color='k', ls='--', lw=0.8)\n",
    "ax2.set_ylabel(r'PFEL (m$^3$ s$^{-1}$ per 100 m)', fontsize=12)\n",
    "ax2.set_ylim(df['PFEL'].min(), df['PFEL'].max())\n",
    "\n",
    "# --- Shared x-axis formatting ---\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "date_fmt = DateFormatter('%b %Y')\n",
    "ax2.xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Load merged daily CSV ---\n",
    "combined_path = Path('~/Desktop/Summer 2025 Python/bakun_combined_daily.csv').expanduser()\n",
    "df = pd.read_csv(combined_path, parse_dates=['DATE']).sort_values('DATE')\n",
    "\n",
    "# --- Ensure daily frequency if needed (optional) ---\n",
    "# df = df.set_index('DATE').asfreq('D')  # uncomment only if you want explicit daily rows\n",
    "# df = df.reset_index()\n",
    "\n",
    "# --- 15-day rolling means (time-based window) ---\n",
    "df_rolling = df.copy()\n",
    "df_rolling = df_rolling.set_index('DATE')\n",
    "roll_c = df_rolling['C46204'].rolling(window='30D', min_periods=1).mean()\n",
    "roll_p = df_rolling['PFEL'].rolling(window='30D', min_periods=1).mean()\n",
    "\n",
    "# Back to columns\n",
    "roll = pd.DataFrame({'DATE': roll_c.index, 'C46204_roll15': roll_c.values, 'PFEL_roll15': roll_p.values})\n",
    "\n",
    "# --- Compute ranges for subplot sizing (use smoothed series) ---\n",
    "def total_range(series):\n",
    "    if not np.isfinite(series).any():\n",
    "        return 1.0\n",
    "    smin = np.nanmin(series)\n",
    "    smax = np.nanmax(series)\n",
    "    return float((smax - smin) if np.isfinite(smax - smin) and (smax - smin) > 0 else 1.0)\n",
    "\n",
    "range_c = total_range(roll['C46204_roll15'].values)\n",
    "range_p = total_range(roll['PFEL_roll15'].values)\n",
    "height_ratios = [range_c, range_p]\n",
    "\n",
    "# --- Colors by sign of the rolling mean ---\n",
    "colors_c = np.where(roll['C46204_roll15'] >= 0, 'steelblue', 'tomato')\n",
    "colors_p = np.where(roll['PFEL_roll15']   >= 0, 'steelblue', 'tomato')\n",
    "\n",
    "# --- Build figure ---\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    nrows=2, ncols=1, figsize=(12, 8), sharex=True,\n",
    "    gridspec_kw={'height_ratios': height_ratios}\n",
    ")\n",
    "\n",
    "# --- Top: C46204 (15D rolling) ---\n",
    "ax1.bar(roll['DATE'], roll['C46204_roll15'], width=1.0, color=colors_c, align='center')\n",
    "ax1.axhline(0, color='k', ls='--', lw=0.8)\n",
    "ax1.set_ylabel(r'C46204 (15-day mean)  [m$^3$ s$^{-1}$ per 100 m]', fontsize=12)\n",
    "ax1.set_title('Bakun Upwelling Index — 15-day Rolling Averages', fontsize=14)\n",
    "ax1.set_ylim(np.nanmin(roll['C46204_roll15']), np.nanmax(roll['C46204_roll15']))\n",
    "\n",
    "# --- Bottom: PFEL (15D rolling) ---\n",
    "ax2.bar(roll['DATE'], roll['PFEL_roll15'], width=1.0, color=colors_p, align='center')\n",
    "ax2.axhline(0, color='k', ls='--', lw=0.8)\n",
    "ax2.set_ylabel(r'PFEL 51°N, 131°W (15-day mean)  [m$^3$ s$^{-1}$ per 100 m]', fontsize=12)\n",
    "ax2.set_ylim(np.nanmin(roll['PFEL_roll15']), np.nanmax(roll['PFEL_roll15']))\n",
    "\n",
    "# --- Shared x-axis ---\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "date_fmt = DateFormatter('%b %Y')\n",
    "ax2.xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "# --- Load merged daily CSV ---\n",
    "combined_path = Path('~/Desktop/Summer 2025 Python/bakun_combined_daily.csv').expanduser()\n",
    "df = pd.read_csv(combined_path, parse_dates=['DATE']).sort_values('DATE')\n",
    "\n",
    "# --- Filter to overlapping valid data ---\n",
    "df_clean = df.dropna(subset=['C46204', 'PFEL'])\n",
    "\n",
    "# Optional: filter to a specific date range\n",
    "start_date = \"2020-01-01\"\n",
    "end_date   = \"2025-01-01\"\n",
    "mask = (df_clean['DATE'] >= start_date) & (df_clean['DATE'] <= end_date)\n",
    "df_filtered = df_clean.loc[mask]\n",
    "\n",
    "# --- Run linear regression ---\n",
    "x = df_filtered['C46204'].values\n",
    "y = df_filtered['PFEL'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "print(f\"Slope:      {slope:.3f}\")\n",
    "print(f\"Intercept:  {intercept:.3f}\")\n",
    "print(f\"R²:         {r_value**2:.3f}\")\n",
    "print(f\"P-value:    {p_value:.3e}\")\n",
    "print(f\"Std Error:  {std_err:.3f}\")\n",
    "\n",
    "# --- Scatter + regression line ---\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.scatter(x, y, alpha=0.5, label='Daily values')\n",
    "ax.plot(x, slope*x + intercept, color='red', lw=2, label=f'Fit: y = {slope:.2f}x + {intercept:.2f}')\n",
    "ax.set_xlabel('C46204  [m$^3$ s$^{-1}$ per 100 m]')\n",
    "ax.set_ylabel('PFEL  [m$^3$ s$^{-1}$ per 100 m]')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title(f'C46204 vs PFEL ({start_date} to {end_date})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb9b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "# --- Load merged daily CSV ---\n",
    "combined_path = Path('~/Desktop/Summer 2025 Python/bakun_combined_daily.csv').expanduser()\n",
    "df = pd.read_csv(combined_path, parse_dates=['DATE']).sort_values('DATE')\n",
    "\n",
    "# --- Calculate 15-day rolling means ---\n",
    "df['C46204_roll'] = df['C46204'].rolling(window=15, center=True, min_periods=1).mean()\n",
    "df['PFEL_roll']   = df['PFEL'].rolling(window=15, center=True, min_periods=1).mean()\n",
    "df_filled = df.copy()\n",
    "df_filled['C46204_roll'] = df_filled['C46204_roll'].interpolate()\n",
    "df_filled['PFEL_roll']   = df_filled['PFEL_roll'].interpolate()\n",
    "df = df_filled\n",
    "# --- Filter to overlapping valid data ---\n",
    "df_clean = df.dropna(subset=['C46204_roll', 'PFEL_roll'])\n",
    "\n",
    "# Optional: restrict to a specific date range\n",
    "start_date = \"2020-01-01\"\n",
    "end_date   = \"2025-01-01\"\n",
    "mask = (df_clean['DATE'] >= start_date) & (df_clean['DATE'] <= end_date)\n",
    "df_filtered = df_clean.loc[mask]\n",
    "\n",
    "# --- Run linear regression on rolling means ---\n",
    "x = df_filtered['C46204_roll'].values\n",
    "y = df_filtered['PFEL_roll'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "print(f\"Slope:      {slope:.3f}\")\n",
    "print(f\"Intercept:  {intercept:.3f}\")\n",
    "print(f\"R²:         {r_value**2:.3f}\")\n",
    "print(f\"P-value:    {p_value:.3e}\")\n",
    "print(f\"Std Error:  {std_err:.3f}\")\n",
    "\n",
    "# --- Scatter + regression line ---\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.scatter(x, y, alpha=0.6, label='15-day rolling means')\n",
    "ax.plot(x, slope*x + intercept, color='red', lw=2, label=f'Fit: y = {slope:.2f}x + {intercept:.2f}')\n",
    "ax.set_xlabel('C46204 15-day mean [m$^3$ s$^{-1}$ per 100 m]')\n",
    "ax.set_ylabel('PFEL 15-day mean [m$^3$ s$^{-1}$ per 100 m]')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title(f'C46204 vs PFEL (15-day mean, {start_date} to {end_date})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a9e06",
   "metadata": {},
   "source": [
    "# chagpt wants to try some lag analysis #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your combined dataframe with columns 'C46204' and 'PFEL'\n",
    "# and a datetime index, and you've already done the 15-day rolling mean\n",
    "rolling_window = 15\n",
    "df_roll = df[['C46204', 'PFEL']].rolling(window=rolling_window, center=True, min_periods=1).mean()\n",
    "\n",
    "# Drop rows where both are NaN\n",
    "df_roll = df_roll.dropna(subset=['C46204', 'PFEL'])\n",
    "\n",
    "# Function to compute lag correlation\n",
    "def lag_corr(x, y, lag):\n",
    "    if lag > 0:\n",
    "        return x.corr(y.shift(lag))\n",
    "    elif lag < 0:\n",
    "        return x.shift(-lag).corr(y)\n",
    "    else:\n",
    "        return x.corr(y)\n",
    "\n",
    "max_lag = 180  # days\n",
    "lags = np.arange(-max_lag, max_lag+1)\n",
    "correlations = [lag_corr(df_roll['C46204'], df_roll['PFEL'], lag) for lag in lags]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lags, correlations, marker='o')\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Lag (days)\\nPositive = PFEL lags C46204')\n",
    "plt.ylabel('Pearson r')\n",
    "plt.title(f'Lag Correlation (15-day mean, ±{max_lag} days)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4442f54a",
   "metadata": {},
   "source": [
    "# lets do some more linear regressions this time sorta mimicking what jackson et al 2021 did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "import os\n",
    "import cmocean as cm\n",
    "import waypoint_distance as wd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from matplotlib.dates import DateFormatter\n",
    "import gsw\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib widget\n",
    "\n",
    "# cube = xr.open_dataset(os.path.expanduser('~/Desktop/Summer 2025 Python/calvert_cube.nc'))\n",
    "new_cube = xr.open_dataset(os.path.expanduser('~/Desktop/Summer 2025 Python/2024_2025_transect_cube.nc'))\n",
    "new_cube = new_cube.sel(transect=new_cube.transect != '20250317_out')\n",
    "new_cube = new_cube.assign_coords(along=new_cube['along'] - 25500)\n",
    "new_cube = new_cube.assign_coords(along = new_cube['along']* (-1))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def _pick_var(ds, candidates):\n",
    "    \"\"\"Return first existing variable name from candidates list (or None).\"\"\"\n",
    "    for name in candidates:\n",
    "        if name and name in ds.variables:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def _to_named_series(obj, value_col=None, name='index'):\n",
    "    \"\"\"Normalize Series/DataFrame -> Series with DatetimeIndex and name.\"\"\"\n",
    "    if isinstance(obj, pd.Series):\n",
    "        s = obj.copy()\n",
    "        s.index = pd.to_datetime(s.index)\n",
    "        s.name = name if s.name is None else s.name\n",
    "        return s\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        df = obj.copy()\n",
    "        if 'DATE' in df.columns:\n",
    "            df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "            df = df.set_index('DATE')\n",
    "        else:\n",
    "            if not isinstance(df.index, pd.DatetimeIndex):\n",
    "                raise ValueError(\"Index must be datetime or provide a 'DATE' column.\")\n",
    "        if value_col is None:\n",
    "            # choose a likely value column\n",
    "            for guess in ['PFEL', 'C46204', 'Index', 'M', 'value']:\n",
    "                if guess in df.columns:\n",
    "                    value_col = guess\n",
    "                    break\n",
    "        if value_col is None or value_col not in df.columns:\n",
    "            raise ValueError(f\"Specify value_col (available: {df.columns.tolist()})\")\n",
    "        s = df[value_col].astype(float)\n",
    "        s.name = name\n",
    "        return s\n",
    "    raise TypeError(\"pfel/buoy must be a pandas Series or DataFrame.\")\n",
    "\n",
    "def regression_sill_vs_indices(\n",
    "    cube,\n",
    "    sill_along=0.0,\n",
    "    sill_depth=130.0,\n",
    "    pfel=None, pfel_value_col=None,\n",
    "    buoy=None, buoy_value_col=None,\n",
    "    daily=True,           # average to daily means\n",
    "    rolling='15D',        # None or e.g. '15D'\n",
    "    print_preview=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract T/S/O2 at the sill from an xarray cube and regress vs PFEL and C46204 indices.\n",
    "\n",
    "    Returns a DataFrame with: Variable, Index, n, slope, intercept, R2, p, stderr\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- choose variable names present in your cube ----\n",
    "    v_temp = _pick_var(cube, ['potential_temperature', 'temperature'])\n",
    "    v_salt = _pick_var(cube, ['salinity'])\n",
    "    v_oxy  = _pick_var(cube, ['oxygen_concentration', 'dissolved_oxygen_ml_l',\n",
    "                              'oxygen', 'o2'])\n",
    "\n",
    "    if v_temp is None or v_salt is None:\n",
    "        raise ValueError(f\"Could not find required variables. \"\n",
    "                         f\"Found temp={v_temp}, salinity={v_salt}, oxygen={v_oxy}\")\n",
    "\n",
    "    # ---- select sill slice (nearest along, then nearest depth) ----\n",
    "    # Variables are (transect, depth, along); time is (transect, along)\n",
    "    sill_along_val = float(sill_along)\n",
    "    ds_sill_along = cube.sel(along=sill_along_val, method='nearest')\n",
    "\n",
    "    temp_prof = ds_sill_along[v_temp]      # (transect, depth)\n",
    "    salt_prof = ds_sill_along[v_salt]\n",
    "    oxy_prof  = ds_sill_along[v_oxy] if v_oxy is not None else None\n",
    "\n",
    "    temp_sel = temp_prof.sel(depth=sill_depth, method='nearest')  # (transect,)\n",
    "    salt_sel = salt_prof.sel(depth=sill_depth, method='nearest')  # (transect,)\n",
    "    oxy_sel  = oxy_prof.sel(depth=sill_depth, method='nearest') if oxy_prof is not None else None\n",
    "\n",
    "    # times from time(transect, along) at the same along location\n",
    "    tvec = ds_sill_along['time'].values  # (transect,)\n",
    "    times = pd.to_datetime(tvec)\n",
    "\n",
    "    # ---- build DataFrame of sill properties ----\n",
    "    data = {\n",
    "        'time': times,\n",
    "        'temp': np.asarray(temp_sel.values, dtype=float),\n",
    "        'salinity': np.asarray(salt_sel.values, dtype=float),\n",
    "    }\n",
    "    if oxy_sel is not None:\n",
    "        data['oxygen'] = np.asarray(oxy_sel.values, dtype=float)\n",
    "\n",
    "    df = pd.DataFrame(data).set_index('time').sort_index()\n",
    "\n",
    "    # optional daily averaging (PFEL & buoy are daily)\n",
    "    if daily:\n",
    "        df = df.resample('D').mean()\n",
    "\n",
    "    # optional rolling mean\n",
    "    if rolling:\n",
    "        df = df.rolling(rolling, min_periods=1).mean()\n",
    "\n",
    "    # ---- normalize external indices to Series ----\n",
    "    series_list = []\n",
    "    if pfel is not None:\n",
    "        s_pfel = _to_named_series(pfel, value_col=pfel_value_col, name='PFEL')\n",
    "        if rolling:\n",
    "            s_pfel = s_pfel.rolling(rolling, min_periods=1).mean()\n",
    "        series_list.append(s_pfel)\n",
    "    if buoy is not None:\n",
    "        s_buoy = _to_named_series(buoy, value_col=buoy_value_col, name='C46204')\n",
    "        if rolling:\n",
    "            s_buoy = s_buoy.rolling(rolling, min_periods=1).mean()\n",
    "        series_list.append(s_buoy)\n",
    "\n",
    "    # ---- regressions ----\n",
    "    results = []\n",
    "    for s in series_list:\n",
    "        merged = df.join(s.rename('index'), how='inner')\n",
    "        for var in ['temp', 'oxygen', 'salinity']:\n",
    "            if var not in merged.columns:\n",
    "                continue\n",
    "            x = merged['index'].to_numpy()\n",
    "            y = merged[var].to_numpy()\n",
    "            m = np.isfinite(x) & np.isfinite(y)\n",
    "            if m.sum() < 3:\n",
    "                continue\n",
    "            slope, intercept, r, p, stderr = stats.linregress(x[m], y[m])\n",
    "            results.append({\n",
    "                'Variable': var,\n",
    "                'Index': s.name,\n",
    "                'n': int(m.sum()),\n",
    "                'slope': slope,\n",
    "                'intercept': intercept,\n",
    "                'R2': r**2,\n",
    "                'p': p,\n",
    "                'stderr': stderr\n",
    "            })\n",
    "\n",
    "    if not results:\n",
    "        raise RuntimeError(\"No valid regressions computed. \"\n",
    "                           \"Check variable names, time alignment, or data coverage.\")\n",
    "\n",
    "    out = pd.DataFrame(results).sort_values(['Variable', 'Index']).reset_index(drop=True)\n",
    "    if print_preview:\n",
    "        print(out.to_string(index=False))\n",
    "    return out\n",
    "\n",
    "# pfel_daily: columns ['DATE','PFEL']\n",
    "# buoy_daily: columns ['DATE','C46204']\n",
    "\n",
    "results = regression_sill_vs_indices(\n",
    "    cube=new_cube,\n",
    "    sill_along=0,                # your sill along-location (m)\n",
    "    sill_depth=130,              # target depth (m), nearest used\n",
    "    pfel=pfel_daily,  pfel_value_col='PFEL',\n",
    "    buoy=buoy_daily,  buoy_value_col='C46204',\n",
    "    daily=True,                  # average glider to daily to match indices\n",
    "    rolling='15D'                # apply same 15-day smoothing to both sides\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d89842",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d7159",
   "metadata": {},
   "source": [
    "# i got a blank space babyyyy and i'll write your name #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.max(ds['WSPD']) * 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ab3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# Load the data\n",
    "file_path = '~/Desktop/Summer 2025 Python/c46204.csv'\n",
    "ds = pd.read_csv(file_path)\n",
    "\n",
    "# Parse datetime\n",
    "ds['DATE'] = pd.to_datetime(ds['DATE'], format='%m/%d/%Y %H:%M')\n",
    "ds = ds[(ds['DATE'] >= '2023-01-01') & (ds['DATE'] <= '2024-01-01')]\n",
    "\n",
    "# Convert wind columns to numeric\n",
    "ds['WDIR'] = pd.to_numeric(ds['WDIR'], errors='coerce')\n",
    "ds['WSPD'] = pd.to_numeric(ds['WSPD'], errors='coerce')\n",
    "\n",
    "# Set datetime index\n",
    "ds.set_index('DATE', inplace=True)\n",
    "\n",
    "# Keep only numeric columns we want to resample\n",
    "daily = ds[['WSPD', 'WDIR']].resample('1D').mean()\n",
    "monthly = ds[['WSPD', 'WDIR']].resample('1M').mean()\n",
    "weekly = ds[['WSPD', 'WDIR']].resample('1W').mean()\n",
    "\n",
    "# Plot daily wind speed\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(daily.index, daily['WSPD'], width=0.8, color='blue')\n",
    "ax.set_ylabel('Wind Speed (m/s)', color='blue')\n",
    "ax.set_title('Daily Mean Wind Speed from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b %d\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot daily wind direction\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(daily.index, daily['WDIR'], width=0.8, color='orange')\n",
    "ax.set_ylabel('Wind Direction (°)', color='orange')\n",
    "ax.set_title('Daily Mean Wind Direction from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b %d\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot montly wind speed\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(monthly.index, monthly['WSPD'], color='blue')\n",
    "ax.set_ylabel('Wind Speed (m/s)', color='blue')\n",
    "ax.set_title('Monthly Mean Wind Speed from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b %d\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot monthly wind direction\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(monthly.index, monthly['WDIR'], color='orange')\n",
    "ax.set_ylabel('Wind Direction (°)', color='orange')\n",
    "ax.set_title('Monthly Mean Wind Direction from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "ax.xaxis.set_major_locator(MonthLocator(bymonth=[1, 7]))  # Jan, May, Sep\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot weekly wind speed\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(weekly.index, weekly['WSPD'], color='blue')\n",
    "ax.set_ylabel('Wind Speed (m/s)', color='blue')\n",
    "ax.set_title('Weekly Mean Wind Speed from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b %d\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot weekly wind direction\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(weekly.index, weekly['WDIR'], color='orange')\n",
    "ax.set_ylabel('Wind Direction (°)', color='orange')\n",
    "ax.set_title('Weekly Mean Wind Direction from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "ax.xaxis.set_major_locator(MonthLocator(bymonth=[1, 7]))  # Jan, May, Sep\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "\n",
    "# Plot weekly wind speed as a bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(weekly.index, weekly['WSPD'], width=6, color='blue', align='center')\n",
    "ax.set_ylabel('Wind Speed (m/s)', color='blue')\n",
    "ax.set_title('Weekly Mean Wind Speed from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b %d\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot weekly wind direction as a bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(weekly.index, weekly['WDIR'], width=6, color='orange', align='center')\n",
    "ax.set_ylabel('Wind Direction (°)', color='orange')\n",
    "ax.set_title('Weekly Mean Wind Direction from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_locator(MonthLocator(bymonth=[1, 7]))  # Jan, July ticks\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 7-day rolling means\n",
    "rolling = ds[['WSPD', 'WDIR']].rolling('7D').mean()\n",
    "\n",
    "# Wind Speed: bar plot of 7-day rolling mean\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(rolling.index, rolling['WSPD'], width=1, color='blue', align='center')\n",
    "ax.set_ylabel('Wind Speed (m/s)', color='blue')\n",
    "ax.set_title('7-Day Rolling Mean Wind Speed from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wind Direction: bar plot of 7-day rolling mean\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(rolling.index, rolling['WDIR'], width=1, color='orange', align='center')\n",
    "ax.set_ylabel('Wind Direction (°)', color='orange')\n",
    "ax.set_title('7-Day Rolling Mean Wind Direction from C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# Step 1: 7-day rolling mean (daily resolution)\n",
    "rolling = ds[['WSPD', 'WDIR']].rolling('7D').mean()\n",
    "\n",
    "# Step 2: Resample the rolling means to 1-week frequency\n",
    "weekly_from_rolling = rolling.resample('1W').mean()\n",
    "\n",
    "# Step 3a: Plot weekly wind speed (smoothed)\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(weekly_from_rolling.index, weekly_from_rolling['WSPD'], width=6, color='blue')\n",
    "ax.set_ylabel('Wind Speed (m/s)', color='blue')\n",
    "ax.set_title('Weekly Mean Wind Speed (from 7-Day Rolling) – C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 3b: Plot weekly wind direction (smoothed)\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(weekly_from_rolling.index, weekly_from_rolling['WDIR'], width=6, color='orange')\n",
    "ax.set_ylabel('Wind Direction (°)', color='orange')\n",
    "ax.set_title('Weekly Mean Wind Direction (from 7-Day Rolling) – C46204')\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b\\n%Y'))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and parse\n",
    "file_path = '~/Desktop/Summer 2025 Python/c46204.csv'\n",
    "ds = pd.read_csv(file_path)\n",
    "ds['DATE'] = pd.to_datetime(ds['DATE'], format='%m/%d/%Y %H:%M')\n",
    "ds = ds[ds['DATE'] >= '2020-01-01']\n",
    "\n",
    "# Convert wind direction and speed to numeric\n",
    "ds['WDIR'] = pd.to_numeric(ds['WDIR'], errors='coerce')\n",
    "ds['WSPD'] = pd.to_numeric(ds['WSPD'], errors='coerce')\n",
    "\n",
    "# Classify wind direction into regimes\n",
    "def classify_wind_dir(wdir):\n",
    "    if pd.isna(wdir):\n",
    "        return 'Other'\n",
    "    elif 300 <= wdir <= 340:\n",
    "        return 'Upwelling'\n",
    "    elif 120 <= wdir <= 160:\n",
    "        return 'Downwelling'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "ds['WindCategory'] = ds['WDIR'].apply(classify_wind_dir)\n",
    "\n",
    "# Set datetime index\n",
    "ds.set_index('DATE', inplace=True)\n",
    "\n",
    "# Count days per week by category\n",
    "weekly_counts = ds.groupby([pd.Grouper(freq='1W'), 'WindCategory']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot stacked bar of Upwelling vs Downwelling counts\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "weekly_counts[['Upwelling', 'Downwelling']].plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    ax=ax,\n",
    "    color=['blue', 'orange'],\n",
    "    width=0.8\n",
    ")\n",
    "\n",
    "ax.set_title('Weekly Counts of Upwelling vs Downwelling-Favorable Winds')\n",
    "ax.set_ylabel('Hourly Observations per Week')\n",
    "ax.set_xlabel('Week')\n",
    "ax.legend(title='Wind Regime')\n",
    "ax.set_xticks(range(0, len(weekly_counts), 4))\n",
    "ax.set_xticklabels(\n",
    "    [d.strftime('%b\\n%Y') for d in weekly_counts.index[::4]],\n",
    "    rotation=45\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f306f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
